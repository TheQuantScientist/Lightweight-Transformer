{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495e5cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('IBM.csv')\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "normalized_data = scaler.fit_transform(data['Close'].values.reshape(-1, 1)).flatten() # Assuming 'Close' is the column you want to predict\n",
    "\n",
    "# Data Preprocessing Function modified for multi-step\n",
    "def create_sequences(data, sequence_length, steps):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - sequence_length - steps + 1):\n",
    "        x = data[i:(i + sequence_length)]\n",
    "        y = data[i + sequence_length:i + sequence_length + steps]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# Create sequences with modified function\n",
    "sequence_length = 1  # Updated sequence length for your use case\n",
    "steps = 1  # Number of future steps to predict\n",
    "X, y = create_sequences(normalized_data, sequence_length, steps)\n",
    "\n",
    "# Split the data\n",
    "split = int(len(X) * 0.9)\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "# Reshape for LSTM [samples, time steps, features]\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(sequence_length, 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(steps))  # The output layer should have 'steps' units if predicting multiple steps\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(0.001), loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=64, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "# Predicting\n",
    "train_predict = model.predict(X_train)\n",
    "test_predict = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae_train = mean_absolute_error(y_train, train_predict)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, train_predict))\n",
    "\n",
    "mae_test = mean_absolute_error(y_test, test_predict)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, test_predict))\n",
    "\n",
    "print(f\"Training Data - MAE: {mae_train}, RMSE: {rmse_train}\")\n",
    "print(f\"Testing Data - MAE: {mae_test}, RMSE: {rmse_test}\")\n",
    "\n",
    "# If you want to plot the predictions (optional)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(y_test)\n",
    "plt.plot(test_predict)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3591ab80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM-CNN \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load the data from a CSV file\n",
    "data_path = 'IBM.csv'  # Update this to the correct path where IBM.csv is located\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Assuming 'Close' is the column you want to predict, adjust if needed\n",
    "data = data['Close'].values.reshape(-1, 1)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "normalized_data = scaler.fit_transform(data).flatten()\n",
    "\n",
    "# Data Preprocessing Function for multi-step\n",
    "def create_sequences(data, sequence_length, steps):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - sequence_length - steps + 1):\n",
    "        x = data[i:(i + sequence_length)]\n",
    "        y = data[i + sequence_length:i + sequence_length + steps]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# Create sequences with modified function\n",
    "sequence_length = 7  # This is the window size of your sequence\n",
    "steps = 1  # This is the prediction horizon\n",
    "X, y = create_sequences(normalized_data, sequence_length, steps)\n",
    "\n",
    "# Split the data\n",
    "split = int(len(X) * 0.9)\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "# Reshape for LSTM-CNN [samples, time steps, features]\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Define the LSTM-CNN model\n",
    "model = Sequential()\n",
    "\n",
    "# LSTM layer with return_sequences=True for the following CNN layers\n",
    "model.add(LSTM(64, input_shape=(sequence_length, 1), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# CNN layers\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "\n",
    "# Final dense layers\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(steps))  # Adjust 'steps' if you're predicting more than one future step\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(0.001), loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=64, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "# Predictions\n",
    "train_predict = model.predict(X_train)\n",
    "test_predict = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using MAE and RMSE\n",
    "mae_train = mean_absolute_error(y_train, train_predict)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, train_predict))\n",
    "\n",
    "mae_test = mean_absolute_error(y_test, test_predict)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, test_predict))\n",
    "\n",
    "print(f\"Training Data - MAE: {mae_train}, RMSE: {rmse_train}\")\n",
    "print(f\"Testing Data - MAE: {mae_test}, RMSE: {rmse_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56684cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVR\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Load the data\n",
    "data_path = 'lorenz.txt'  # Update this to the correct path where lorenz.txt is located\n",
    "data = np.loadtxt(data_path)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "normalized_data = scaler.fit_transform(data.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Data Preprocessing Function modified for multi-step\n",
    "def create_sequences(data, sequence_length, steps):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - sequence_length - steps + 1):\n",
    "        x = data[i:(i + sequence_length)]\n",
    "        y = data[i + sequence_length:i + sequence_length + steps]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# Create sequences with modified function\n",
    "sequence_length = 1  \n",
    "steps = 1  # Number of future steps to predict\n",
    "X, y = create_sequences(normalized_data, sequence_length, steps)\n",
    "\n",
    "# Split the data\n",
    "split = int(len(X) * 0.9)\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "# Instantiate and fit the SVR model\n",
    "# Note: You may want to tune these hyperparameters\n",
    "svr_rbf = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)\n",
    "svr_rbf.fit(X_train, y_train.ravel())\n",
    "\n",
    "# Predictions\n",
    "train_predict = svr_rbf.predict(X_train)\n",
    "test_predict = svr_rbf.predict(X_test)\n",
    "\n",
    "# Evaluate the model using MAE and RMSE on the scaled data\n",
    "mae_train = mean_absolute_error(y_train, train_predict)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, train_predict))\n",
    "\n",
    "mae_test = mean_absolute_error(y_test, test_predict)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, test_predict))\n",
    "\n",
    "print(f\"Training Data - MAE: {mae_train}, RMSE: {rmse_train}\")\n",
    "print(f\"Testing Data - MAE: {mae_test}, RMSE: {rmse_test}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
